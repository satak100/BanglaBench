# BanglaBench
BanglaBench explores the necessity of Bengali-specific large language models (LLMs) by benchmarking open-weight and closed-source LLMs like LLaMA-3 and GPT-4 against fine-tuned encoder-decoder models on diverse Bengali NLP tasks, including translation, summarization, and question-answering. The findings highlight key challenges such as inefficient tokenization of Bengali script and biases in machine-translated datasets, emphasizing the urgent need for a dedicated Bengali LLM backed by high-quality pretraining and instruction-tuning datasets.
